Introduction:

From a time where newspapers were the major means of mass communication, to the ever developing world of internet, not only the modes of mass communication have increased but also the accessibility of information has become easier. This however has given rise to multiple problems like disorganization, relevance issues, misinformation. Therefore, this master thesis analyses German News articles taken from an Austrian newspaper and aims to set up a transformer-based NLP model, which is able to automatically classify such documents in one or more self defined classes aiming to advance the fieldâ€™s understanding and capabilities in processing and categorizing news articles in the German language. Specifically, the goal of this thesis is to contribute some technological resource for German language as it is an internationally important language and commands global importance across diverse sectors. Major parts of the Europe have German as their primary language. Therefore, we evaluate two models, one monolingual that is RoBERTa and the other is the multilingual version of RoBERTa, that is, XLM-RoBERTa on the 10KGNAD dataset. The results of this thesis reveal promising advancements in German news text classification, paving the way for more accurate and efficient news categorization systems. The findings contribute significantly to the broader field of NLP and offer practical implications for news organizations, content recommendation engines, and information retrieval systems operating in the German-speaking digital landscape.

